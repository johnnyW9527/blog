

#### 8 Kafka实战

##### 8.1 消息的偏移量和顺序消费

>**消息的偏移量**
>
>消息的发送⽅会把消息发送到broker中，broker会存储消息，消息是按照发送的顺序进⾏存储。因此消费者在消费消息时可以指明主题中消息的偏移量。默认情况下，是从最后⼀个消息的下⼀个偏移量开始消费
>
>**顺序消费原理**
>
>* ⽣产者将消息发送给broker，broker会将消息保存在本地的⽇志⽂件中
>* 消息的保存是有序的，通过offset偏移量来描述消息的有序性
>* 消费者消费消息时也是通过offset来描述当前要消费的那条消息的位置

##### 8.2 主题和分区的概念

> **主题Topic**
>
> 主题-topic在kafka中是⼀个逻辑的概念，kafka通过topic将消息进⾏分类。不同的topic会被订阅该topic的消费者消费。
>
> **分区partition**
>
> 通过partition将一个topic中的消息分区来存储
>
> * 分区存储，可以解决统⼀存储⽂件过⼤的问题
> * 提供了读写的吞吐量：读和写可以同时在多个分区中进⾏
>
> **kafka中消息日志文件中保存的内容**
>
> * 00000.log： 这个⽂件中保存的就是消息
> * __consumer_offsets-49:kafka内部⾃⼰创建了__consumer_offsets主题包含了50个分区。这个主题⽤来存放消费者消费某个主题的偏移量。因为每个消费者都会⾃⼰维护着消费的主题的偏移量，也就是说每个消费者会把消费的主题的偏移量⾃主上报给kafka中的默认主题：consumer_offsets。因此kafka为了提升这个主题的并发性，默认设置了50个分区
> * 提交到哪个分区：通过hash函数：hash(consumerGroupId) % __consumer_offsets主题的分区数
> * 提交到该主题中的内容是：key是consumerGroupId+topic+分区号，value就是当前offset的值
> * ⽂件中保存的消息，默认保存7天。七天到后消息会被删除。

##### 8.3 生产者端的同步发送和异步发送

> **生产者的同步消费**
>
> 如果⽣产者发送消息没有收到ack，⽣产者会阻塞，阻塞到3s的时间，如果还没有收到消息，会进⾏重试。重试的次数3次
>
> **生产者的异步发送消息**
>
> 异步发送，⽣产者发送完消息后就可以执⾏之后的业务，broker在收到消息后异步调⽤⽣产者提供的callback回调⽅法。
>
> 异步发送会存在数据丢失的问题，同步发送更为常用
>
> **生产者中的ack配置**
>
> 在同步发送的前提下，⽣产者在获得集群返回的ack之前会⼀直阻塞。那么集群什么时候返回ack呢？此时ack有3个配置：
>
> * ack = 0 kafka-cluster不需要任何的broker收到消息，就⽴即返回ack给⽣产者，最容易丢消息的，效率是最⾼的
> * ack=1（默认）： 多副本之间的leader已经收到消息，并把消息写⼊到本地的log中，才会返回ack给⽣产者，性能和安全性是最均衡的
> * ack=-1/all。⾥⾯有默认的配置min.insync.replicas=2(默认为1，推荐配置⼤于等于2)，此时就需要leader和⼀个follower同步完后，才会返回ack给⽣产者（此时集群中有2个broker已完成数据的接收），这种⽅式最安全，但性能最差
>
> **发送消息的缓冲区机制**
>
> * kafka默认会创建⼀个消息缓冲区，⽤来存放要发送的消息，缓冲区是32m
> * kafka本地线程会去缓冲区中⼀次拉16k的数据，发送到broker
> * 如果线程拉不到16k的数据，间隔10ms也会将已拉到的数据发到broker

##### 8.4 消费者消费消息的基本实现

> **Offset的自动提交和手动提交**
>
> **提交的内容**
>
> 消费者⽆论是⾃动提交还是⼿动提交，都需要把所属的消费组+消费的某个主题+消费的某个分区及消费的偏移量，这样的信息提交到集群的_consumer_offsets主题⾥⾯
>
> **自动提交**
>
> 消费者poll消息下来就会自动提交offset(⾃动提交会丢消息。因为消费者在消费前提交offset，有可能提交完后还没消费时消费者挂了)
>
> **手动提交**
>
> 需要把自动提交的配置改为false
>
> ```java
> props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");
> ```
>
> * ⼿动同步提交: 在消费完消息后调⽤同步提交的⽅法，当集群返回ack前⼀直阻塞，返回ack后表示提交成功，执⾏之后的逻辑
> * ⼿动异步提交: 在消息消费完后提交，不需要等到集群ack，直接执⾏之后的逻辑，可以设置⼀个回调⽅法，供集群调⽤

##### 8.5 消费者poll消息的细节与消费者心跳配置

> **长轮询poll消息**
>
> 默认情况下，消费者⼀次会poll500条消息。
>
> ```java
> props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);
> ```
>
> 代码中设置了⻓轮询的时间是1000毫秒
>
> * 如果⼀次poll到500条，就直接执⾏for循环
> * 如果这⼀次没有poll到500条。且时间在1秒内，那么⻓轮询继续poll，要么到500条，要么到1s
> * 如果多次poll都没达到500条，且1秒时间到了，那么直接执⾏for循环
> * 如果两次poll的间隔超过30s，集群会认为该消费者的消费能⼒过弱，该消费者被踢出消费组，触发rebalance机制，rebalance机制会造成性能开销。可以通过设置这个参数，让⼀次poll的消息条数少⼀点
>
> **消费者心跳检测配置**
>
> ```java
> //consumer给broker发送⼼跳的间隔时间
> props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);
> 
> //kafka如果超过10秒没有收到消费者的⼼跳，则会把消费者踢出消费组，进⾏ rebalance，
> //把分区分配给其他消费者。
> props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);
> ```

##### 8.6 指定分区和偏移量，时间消费

> **指定分区消费**
>
> 从topic的0号分区最新offset消费
>
> ```java
> consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));
> ```
>
> **从头消费**
>
> 从topic的0号分区的开始offset消费
>
> ```java
> consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));
> consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));
> ```
>
> **指定offset消费**
>
> 从topic的0号分区的10这个offset开始消费
>
> ```java
> consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));
> consumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);
> ```
>
> **指定时间消费**
>
> 根据时间，去所有的partition中确定该时间对应的offset，然后去所有的partition中找到该offset之后的消息开始消费。
>
> ```java
> List<PartitionInfo> topicPartitions = consumer.partitionsFor(TOPIC_NAME);
> //从1小时前开始消费
> long fetchDataTime = new Date().getTime() - 1000 * 60 * 60;
> 
> Map<TopicPartition, Long> map = new HashMap<>();
> for (PartitionInfo par : topicPartitions) {
>    
>      
>     map.put(new TopicPartition(TOPIC_NAME, par.partition()), fetchDataTime);
> }
> 
> Map<TopicPartition, OffsetAndTimestamp> parMap = consumer.offsetsForTimes(map);
> for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : parMap.entrySet()) {
>    
>      
>     TopicPartition key = entry.getKey();
>     OffsetAndTimestamp value = entry.getValue();
>     if (key == null || value == null) continue;
>     Long offset = value.offset();
>     System.out.println("partition-" + key.partition() + "|offset-" + offset);
>     System.out.println();
>     //根据消费⾥的timestamp确定offset
>     if (value != null) {
>    
>      
>         consumer.assign(Arrays.asList(key));
>         consumer.seek(key, offset);
>     }
> }
> ```
>
> **新消费者组的消费offset规则**
>
> 新消费组中的消费者在启动以后，默认会从当前分区的最后⼀条消息的offset+1开始消费（消费新消息）。可以通过以下的设置，让新的消费者第⼀次从头开始消费。之后开始消费新消息（最后消费的位置的偏移量+1）
>
> * latest：默认的，消费新消息
> * earliest：第⼀次从头开始消费。之后开始消费新消息（最后消费的位置的偏移量+1）

##### 8.7 Kafka中Controller、Rebalance、HW、LEO的概念

> **Controller**
>
> 集群中谁来充当controller:
>
> 每个broker启动时会向zk创建⼀个临时序号节点，获得的序号最⼩的那个broker将会作为集群中的controller，负责这么⼏件事
>
> * 当集群中有⼀个副本的leader挂掉，需要在集群中选举出⼀个新的leader，选举的规则是从isr集合中最左边获得
> * 当集群中有broker新增或减少，controller会同步信息给其他broker
> * 当集群中有分区新增或减少，controller会同步信息给其他broker
>
> **Rebalance机制**
>
> * 前提：消费组中的消费者没有指明分区来消费
> * 触发的条件：当消费组中的消费者和分区的关系发⽣变化的时候
> * 分区分配的策略：在rebalance之前，分区怎么分配会有这么三种策略
> * range：根据公示计算得到每个消费消费哪⼏个分区：前⾯的消费者是分区总数/消费
>   者数量+1,之后的消费者是分区总数/消费者数量
> * 轮询：⼤家轮着来
> * sticky：粘合策略，如果需要rebalance，会在之前已分配的基础上调整，不会改变之前的分配情况。如果这个策略没有开，那么就要进⾏全部的重新分配。建议开启。
>
> **HW和LEO**
>
> * LEO是某个副本最后消息的消息位置（log-end-offset）
> * HW是已完成同步的位置。消息在写⼊broker时，且每个broker完成这条消息的同步后，hw才会变化。在这之前消费者是消费不到这条消息的。在同步完成之后，HW更新之后，消费者才能消费到这条消息，这样的⽬的是防⽌消息的丢失

##### 8.8 Kafka优化之防止消息丢失和重复消费

> **如何防止消费丢失**
>
> * ⽣产者：1）使⽤同步发送 2）把ack设成1或者all，并且设置同步的分区数>=2
> * 消费者：把⾃动提交改成⼿动提交
>
> **如何防止重复消费**
>
> 在防⽌消息丢失的⽅案中，如果⽣产者发送完消息后，因为⽹络抖动，没有收到ack，但实际上broker已经收到了。
>
> 此时⽣产者会进⾏重试，于是broker就会收到多条相同的消息，⽽造成消费者的重复消费。
>
> 怎么解决：
>
> * ⽣产者关闭重试：会造成丢消息（不建议）
> * 消费者解决⾮幂等性消费问题：所谓的幂等性：多次访问的结果是⼀样的。对于rest的请求（get（幂等）、post（⾮幂等）、put（幂等）、delete（幂等））
>
> 1. 在数据库中创建联合主键，防⽌相同的主键创建出多条记录
> 2. 使⽤分布式锁，以业务id为锁。保证只有⼀条记录能够创建成功
>
> **Kafka优化之顺序消费的实现**
>
> * ⽣产者：保证消息按顺序发送，且消息不丢失
> * 使⽤同步的发送
> * ack设置成⾮0的值
> * 开启重试
> * 消费者：主题只能设置⼀个分区，消费组中只能有⼀个消费者
> * kafka的顺序消费使⽤场景不多，因为牺牲掉了性能，但是⽐如rocketmq在这⼀块有专⻔的功能已设计好
>
> **消息积压问题**
>
> 消息的消费者的消费速度远赶不上⽣产者的⽣产消息的速度，导致kafka中有⼤量的数据没有被消费。随着没有被消费的数据堆积越多，消费者寻址的性能会越来越差，最后导致整个kafka对外提供的服务的性能很差，从⽽造成其他服务也访问速度变慢，造成服务雪崩
>
> 解决方案
>
> * 在这个消费者中，使⽤多线程，充分利⽤机器的性能进⾏消费消息。
> * 通过业务的架构设计，提升业务层⾯消费的性能。
> * 创建多个消费组，多个消费者，部署到其他机器上，⼀起消费，提⾼消费者的消费速度
> * 创建⼀个消费者，该消费者在kafka另建⼀个主题，配上多个分区，多个分区再配上多个消费者。该消费者将poll下来的消息，不进⾏消费，直接转发到新建的主题上。此时，新的主题的多个分区的多个消费者就开始⼀起消费了。——不常⽤
>
> **实现延时队列**
>
> 场景： 订单创建后，超过30分钟没有⽀付，则需要取消订单，这种场景可以通过延时队列来实现
>
> 方案：
>
> ![](C:\study\mlog\picture\28.PNG)
>
> * kafka中创建相应的主题
> * 消费者消费该主题的消息（轮询）
> * 消费者消费消息时判断消息的创建时间和当前时间是否超过30分钟（前提是订单没⽀付）
> * 如果是：去数据库中修改订单状态为已取消
> * 如果否：记录当前消息的offset，并不再继续消费之后的消息。等待1分钟后，再次向kafka拉取该offset及之后的消息，继续进⾏判断，以此反复

##### 8.9 Kafka生产者之生产经验

> **生产者如何提高吞吐量**
>
> 由于linger.ms默认为0，即缓冲区队列中一有数据就sender线程就将其拉出到Kafka集群，效率比较低，提高生产者吞吐量有四种方式：
>
> * 扩大**批次的大小batch.size**，默认为16k，当数据积累到batch.size时sender线程才拉取数据。
> * 扩大**sender的等待时间linger.ms**，默认为0ms，可以修改为2-100ms。
> * 对缓冲区队列中的数据进行**压缩再积累**由sender拉取**compression.type**。
> * **扩大缓冲区大小RecordAccumulator**，默认为32M，修改为64M。
>
> **数据可靠性**
>
> ACK应答级别0、1、-1
>
> Leader收到数据，所有Follower都开始同步数据，但有一个**Follower**，因为某种故障，迟迟不能与Leader进行同步
>
> 解决：**Leader维护了一个动态的in-sync replica set（ISR），意为和Leader保持同步的Follower+Leader集合**(leader：0，isr:0,1,2)。
>
> 如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该**时间阈值**由**replica.lag.time.max.ms参数设定**，**默认30s**。例如2超时，(leader:0, isr:0,1)。这样就不用等长期联系不上或者已经故障的节点。
>
> 如果分区副本设置为1个，或者ISR里应答的最小副本数量（ min.insync.replicas 默认为1）设置为1，和ack=1的效果是一样的，仍然有丢数的风险（leader：0，isr:0）。
>
> **数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量>=2**
>
> acks=-1或all时，生产者发送数据给Leader，Leader接受到数据后返回确认ack给生产者并同步数据到副本，此时Leader挂了，但是生产者并没有接收到返回的ack，所以生产者重新给新的Leader发送数据，导致数据重复
>
> **数据去重**
>
> acks=-1或all时，生产者发送数据给Leader，Leader接受到数据后返回确认ack给生产者并同步数据到副本，此时Leader挂了，但是生产者并没有接收到返回的ack，所以生产者重新给新的Leader发送数据，导致数据重复
>
> * 数据传递语义
>
> 1.  至少一次（At Least Once），可以保证数据不丢失，但是不能保证数据不重复。至少一次（At Least Once）= ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2
> 2. 最多一次（At Most Once），可以保证数据不重复，但是不能保证数据不丢失最多一次（At Most Once）= ACK级别设置为0
> 3. 精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据**既不能重复也不丢失。**
>    Kafka 0.11版本以后，引入**幂等性和事务**
>
> * 幂等性
>
> **幂等性**就是指Producer不论向Broker发送多少次重复数据，**Broker端都只会持久化一条**，保证了不重复。
>
> **精确一次（Exactly Once） = 幂等性+ 至少一次（ ack=-1 + 分区副本数>=2 + ISR最小副本数量>=2）**
>
> 重复数据的判断标准：
> 具有<PID, Partition, SeqNumber>相同主键的消息提交时，Broker只会持久化一条。其
> 中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。所以幂等性只能保证的是在**单分区单会话内不重复**。
>
> 使用幂等性：
> 开启参数 **enable.idempotence** 默认为 true，false 关闭。
>
> * 生产者事务
>
> 开启事务必须要先开启幂等性。
> Producer 在使用事务功能前，必须先自定义一个唯一的 transactional.id。有了 transactional.id，即使客户端挂掉了，它重启后也能继续处理未完成的事务
>
> ![](C:\study\mlog\picture\29.PNG)
>
> Kafka事务一共有如下5个Api
>
> ```java
> // 1 初始化事务
> void initTransactions();
> 
> // 2 开启事务
> void beginTransaction()throws ProducerFencedException;
> 
> // 3 在事务内提交已经消费的偏移量（主要用于消费者）
> void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,String consumerGroupId) throws ProducerFencedException;
> 
> // 4 提交事务
> void commitTransaction()throws ProducerFencedException;
> 
> // 5 放弃事务（类似于回滚事务的操作）
> void abortTransaction()throws ProducerFencedException;
> ```
>
> 单个Producer，使用事务保证消息的仅一次发送。
>
> ```java
> package com.study.kafka.producer;
> 
> import org.apache.kafka.clients.producer.KafkaProducer;
> import org.apache.kafka.clients.producer.ProducerConfig;
> import org.apache.kafka.clients.producer.ProducerRecord;
> import org.apache.kafka.common.errors.ProducerFencedException;
> import org.apache.kafka.common.serialization.StringSerializer;
> 
> import java.util.Properties;
> 
> public class CustomProducerTransactions {
>    
>      
>     public static void main(String[] args) {
>    
>      
>         //0.创建 kafka 生产者的配置对象
>         Properties properties = new Properties();
> 
>         //给 kafka 配置对象添加配置信息：bootstrap.servers
>         properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
> 
>         // key,value 序列化（必须）：key.serializer，value.serializer
>         properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
>         properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());
> 
>         // 设置事务 id（必须），事务 id 任意起名，全局唯一
>         properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,"transaction_id_01");
> 
>         //1.创建 kafka 生产者对象
>         KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
> 
>         // 初始化事务
>         kafkaProducer.initTransactions();
> 
>         // 开启事务
>         kafkaProducer.beginTransaction();
> 
>         try {
>    
>      
>             //2.调用 send 方法,发送消息
>             for (int i = 0; i < 3; i++) {
>    
>      
>                 kafkaProducer.send(new ProducerRecord<>("first","test"+i));
>             }
>             // 提交事务
>             kafkaProducer.commitTransaction();
>         } catch (ProducerFencedException e) {
>    
>      
>             // 终止事务
>             kafkaProducer.abortTransaction();
>         } finally {
>    
>      
>             //3.关闭资源
>             kafkaProducer.close();
>         }
> 
>     }
> }
> ```
>
> * 数据有序
>
> 消费者接收到的：单分区内有序，多分区间无序
>
> * 数据乱序
>
> 生产者端中每个节点的每个队列最多缓存5个请求，在Kafka集群没有回应的情况下最多可以发送5个数据。若前有个数据发送失败，但其前面的数据发送成功，其后数据正常发送，且发送该数据会重试，导致数据到达Kafka集群时出现乱序。
>
> 解决
>
> 1. kafka在1.x版本之前保证数据单分区有序，条件如下：
>    max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）。
> 2. kafka在1.x及以后版本保证数据单分区有序，条件如下：
>    （i）未开启幂等性：max.in.flight.requests.per.connection需要设置为1。
>    （ii）开启幂等性：max.in.flight.requests.per.connection需要设置小于等于5。
>    原因说明：
>    因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，缓存5个数据后再进行排序。故无论如何，都可以保证最近5个request的数据都是有序的。



