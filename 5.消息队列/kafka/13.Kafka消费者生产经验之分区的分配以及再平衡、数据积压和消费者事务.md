#### 13 消费者生产经验之分区的分配及再平衡、数据积压和消费者事务

##### 13.1 分区的分配及再平衡

> 一个consumer group中有多个consumer组成，一个 topic有多个partition组成，使用分区分配策略决定由哪个consumer来消费哪个partition的数据。
>
> Kafka有四种主流的分区分配策略： Range、RoundRobin、Sticky、CooperativeSticky。
>
> 通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是Range + CooperativeSticky。Kafka可以同时使用多个分区策略。
>
> 分区分配策略用于消费者组初始化流程中的消费者组中的消费者Leader制定消费方案。
>
> | 参数名称                      | 描述                                                         |
> | ----------------------------- | ------------------------------------------------------------ |
> | heartbeat.interval.ms         | Kafka消费者和coordinator之间的心跳时间，默认3s。该条目的值必须小于session.timeout.ms，也应该高于session.timeout.ms的1/3 |
> | session.timeout.ms            | kafka消费者和coordinator之间连接超时时间，默认45s。超过该值，该消费者被移除，消费者组执行再平衡。 |
> | max.poll.interval.ms          | 消费者处理消费的最大时长，默认是5分钟。超过该值，该消费者被移除，消费者组执行再平衡 |
> | partition.assignment.strategy | 消费者分区分配策略，默认策略是Range+CooperativeStricky。Kafka可以同时使用多个分区分配策略。可以选择的策略包括：Range、RoundRobin、Stricky、CooperativeSticky |
>
> * Rang及再平衡
>
> **Range 是对每个 topic 而言的。**
> **1、** 首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。
> **2、** 通过 partitions数/consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。
>
> 缺点： 如果只是针对 1 个 topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有N 多个 topic，那么针对每个 topic，消费者 C0都将多消费 1 个分区，topic越多，C0消费的分区会比其他消费者明显多消费N 个分区。**容易产生数据倾斜。**
>
> * RoundRobin以及再平衡
>
> **RoundRobin 针对集群中所有Topic而言**。
> RoundRobin 轮询分区策略，是把**所有的 partition 和所有的consumer 都列出来**，然后**按照 hashcode 进行排序**，最后通过**轮询算法**来分配 partition 给到各个消费者。
>
> * Sticky以及再平衡
>
> 粘性分区定义：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。
>
> 粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。

##### 13.2 消费者事务

> 如果想完成Consumer端的精准一次性消费，需要Kafka消费端将**消费过程和提交offset过程做原子绑定**。此时我们需要将Kafka的offset保存到支持事务的自定义介质（ 比如 MySQL）

##### 13.3 数据积压（消费者如何提高吞吐量）

> 1. 如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数= 分区数。（两者缺一不可）
> 2. 如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间 < 生产速度），使处理的数据小于生产的数据，也会造成数据积压。
>
> | 参数名称         | 描述                                                         |
> | ---------------- | ------------------------------------------------------------ |
> | fetch.max.bytes  | 默认Default:52428800(50m)。消费者获取服务器端一批消息最大的字节数。如歌服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是有个绝对最大值。一批次的大小受message.max.bytes(brokerconfig) or max.message(topic config)影响 |
> | max.poll.records | 一次poll拉取数据返回消息的最大条数                           |
>
> 